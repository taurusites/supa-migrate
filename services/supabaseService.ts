// services/supabaseService.ts

import { createClient, SupabaseClient } from "@supabase/supabase-js";
import { SchemaInfo, TableSelection } from "../types";

// ---------------------------
// Row‐shape interfaces for RPC
// ---------------------------
interface EnumTypeRow {
  type_schema: string;
  type_name:   string;
  labels:      string[];
}
interface FKRow {
  fk_schema:            string;
  fk_name:              string;
  table_schema:         string;
  table_name:           string;
  column_names:         string[];
  foreign_table_schema: string;
  foreign_table_name:   string;
  foreign_column_names: string[];
}
interface ConstraintRow {
  constraint_name: string;
  definition:      string;
}
interface IndexRow {
  indexdef: string;
}

// -------------------------------------------------
// getClient: build a Supabase client for any schema
// -------------------------------------------------
// NOTE: we cast to `any` to avoid TS errors about the
//   generic `Schema` parameter being a literal union.
function getClient(
  url: string,
  key: string,
  schema: string = "public"
) /* : SupabaseClient<any, any, any> */ {
  return createClient(url, key, {
    db:     { schema },
    global: { headers: { Accept: "application/json" } },
  }) as any;
}

// ---------------------------------------------------------
// 1) listSchemasAndTables: use pg_list_schemas/tables RPCs
// ---------------------------------------------------------
export async function listSchemasAndTables(
  url: string,
  key: string
): Promise<SchemaInfo[]> {
  const supa = getClient(url, key, "public");

  // a) get schemas
  const { data: scRows, error: scErr } = await supa.rpc("pg_list_schemas");
  if (scErr) throw scErr;
  const schemas = (scRows as any[] | null)
    ?.map((r) => r.schema_name as string)
    .filter(Boolean) || [];

  // b) get tables per schema
  const out: SchemaInfo[] = [];
  for (const schema of schemas) {
    const { data: tbRows, error: tbErr } = await supa.rpc(
      "pg_list_tables",
      { schemaname: schema }
    );
    if (tbErr) throw tbErr;
    const tables = (tbRows as any[] | null)
      ?.map((r) => r.table_name as string)
      .filter(Boolean) || [];
    out.push({ schema, tables });
  }
  return out;
}

// ------------------------------------------------------------------
// 2) generateMigrationSQL: ENUMs, DDL, constraints, indexes, FKs, data
// ------------------------------------------------------------------
export async function generateMigrationSQL(
  url: string,
  key: string,
  selections: TableSelection[]
): Promise<string> {
  // RPC client always on "public"
  const rpcClient = getClient(url, key, "public");
  let sql = "-- Generated by Supabase Migration Tool\n\n";

  // 2.1) ENUM types
  {
    const { data: rows, error: err } = await rpcClient.rpc(
      "pg_list_enum_types"
    );
    if (err) throw err;
    (rows as EnumTypeRow[] | null)?.forEach((e) => {
      const vals = e.labels.map((l) => `'${l.replace(/'/g, "''")}'`);
      sql += `CREATE TYPE ${e.type_schema}.${e.type_name} AS ENUM (${vals.join(
        ", "
      )});\n`;
    });
    if (rows && (rows as any[]).length) sql += "\n";
  }

  // 2.2) DDL, constraints, indexes per selected table
  for (const sel of selections.filter((s) => s.selected)) {
    const { schema, table } = sel;

    // a) CREATE TABLE DDL
    {
      const { data: ddlRows, error: ddlErr } = await rpcClient.rpc(
        "pg_get_tabledef",
        { schemaname: schema, tablename: table }
      );
      if (ddlErr) throw ddlErr;
      const ddl = (ddlRows as any[])[0]?.ddl as string;
      sql += `-- DDL for ${schema}.${table}\n${ddl};\n\n`;
    }

    // b) PRIMARY & UNIQUE constraints
    {
      const { data: consRows, error: cErr } = await rpcClient.rpc(
        "pg_list_constraints",
        { schemaname: schema, tablename: table }
      );
      if (cErr) throw cErr;
      (consRows as ConstraintRow[] | null)?.forEach((c) => {
        sql += `ALTER TABLE ${schema}.${table}\n  ADD CONSTRAINT ${c.constraint_name} ${c.definition};\n`;
      });
      if (consRows && (consRows as any[]).length) sql += "\n";
    }

    // c) Non-constraint indexes
    {
      const { data: idxRows, error: iErr } = await rpcClient.rpc(
        "pg_list_indexes",
        { schemaname: schema, tablename: table }
      );
      if (iErr) throw iErr;
      (idxRows as IndexRow[] | null)?.forEach((ix) => {
        sql += ix.indexdef.trim() + ";\n";
      });
      if (idxRows && (idxRows as any[]).length) sql += "\n";
    }
  }

  // 2.3) All FOREIGN KEYS
  {
    const { data: fkRows, error: fkErr } = await rpcClient.rpc(
      "pg_list_foreign_keys"
    );
    if (fkErr) throw fkErr;
    (fkRows as FKRow[] | null)?.forEach((fk) => {
      const cols  = fk.column_names.join(", ");
      const fcols = fk.foreign_column_names.join(", ");
      sql += `ALTER TABLE ${fk.table_schema}.${fk.table_name}\n`
           + `  ADD CONSTRAINT ${fk.fk_name}\n`
           + `  FOREIGN KEY (${cols}) REFERENCES ${fk.foreign_table_schema}.${fk.foreign_table_name}(${fcols});\n\n`;
    });
  }

  // 2.4) Data INSERTS (paginated, per‐schema client)
  for (const sel of selections.filter((s) => s.selected)) {
    const { schema, table } = sel;
    const dataClient = getClient(url, key, schema);
    const pageSize = 500;
    let offset = 0;

    while (true) {
      const { data: batch, error: dErr } = await dataClient
        .from(table)
        .select("*")
        .range(offset, offset + pageSize - 1);

      if (dErr) throw dErr;
      if (!batch || (batch as any[]).length === 0) break;

      const cols = Object.keys((batch as any[])[0]);
      const vals = (batch as any[]).map((row) => {
        return "("
          + cols
              .map((c) => {
                const v = row[c];
                if (v === null) return "NULL";
                if (typeof v === "string") return `'${v.replace(/'/g, "''")}'`;
                return v.toString();
              })
              .join(", ")
          + ")";
      });

      sql += `-- Data for ${schema}.${table} OFFSET ${offset}\n`;
      sql += `INSERT INTO ${schema}.${table} (${cols.join(
        ", "
      )}) VALUES\n${vals.join(",\n")};\n\n`;

      if ((batch as any[]).length < pageSize) break;
      offset += pageSize;
    }
  }

  return sql;
}