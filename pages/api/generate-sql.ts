// pages/api/generate-sql.ts
import type { NextApiRequest, NextApiResponse } from "next";
import { createClient } from "@supabase/supabase-js";
import { TableSelection } from "../../types";

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<string | { error: string }>
) {
  try {
    // 1) Read and validate headers
    const url = req.headers["x-sb-url"] as string;
    const key = req.headers["x-sb-key"] as string;
    if (!url || !key) throw new Error("Missing Supabase URL/key");

    // 2) RPC client (always in 'public' schema)
    const rpcClient = createClient(url, key, {
      global: { headers: { Accept: "application/json" } }
    });

    // 3) Pull selections payload
    const { selections } = req.body as { selections: TableSelection[] };

    let sql = "-- Generated by Supabase Migration Tool\n\n";

    // --- ENUM TYPES ---
    {
      const { data: enumRows, error: enumErr } = await rpcClient.rpc<
        { type_schema: string; type_name: string; labels: string[] }[]
      >("pg_list_enum_types");
      if (enumErr) throw enumErr;
      if (enumRows && enumRows.length) {
        sql += "-- ENUM TYPES\n";
        enumRows.forEach((e) => {
          const vals = e.labels.map((l) => `'${l.replace(/'/g, "''")}'`);
          sql += `CREATE TYPE ${e.type_schema}.${e.type_name} AS ENUM (${vals.join(
            ", "
          )});\n`;
        });
        sql += "\n";
      }
    }

    // --- TABLE DDL + CONSTRAINTS + INDEXES ---
    for (const sel of selections.filter((s) => s.selected)) {
      const { schema, table } = sel;

      // a) CREATE TABLE via RPC
      {
        const { data: ddlRows, error: ddlErr } = await rpcClient.rpc<
          { ddl: string }[]
        >("pg_get_tabledef", { schemaname: schema, tablename: table });
        if (ddlErr) throw ddlErr;
        sql += `-- DDL for ${schema}.${table}\n${ddlRows[0].ddl};\n\n`;
      }

      // b) PRIMARY & UNIQUE constraints
      {
        const { data: consRows, error: consErr } = await rpcClient.rpc<
          { constraint_name: string; definition: string }[]
        >("pg_list_constraints", { schemaname: schema, tablename: table });
        if (consErr) throw consErr;
        if (consRows && consRows.length) {
          sql += `-- Constraints for ${schema}.${table}\n`;
          consRows.forEach((c) => {
            sql += `ALTER TABLE ${schema}.${table}\n  ADD CONSTRAINT ${c.constraint_name} ${c.definition};\n`;
          });
          sql += "\n";
        }
      }

      // c) INDEXES (non‚Äêconstraint)
      {
        const { data: idxRows, error: idxErr } = await rpcClient.rpc<
          { indexdef: string }[]
        >("pg_list_indexes", { schemaname: schema, tablename: table });
        if (idxErr) throw idxErr;
        if (idxRows && idxRows.length) {
          sql += `-- Indexes for ${schema}.${table}\n`;
          idxRows.forEach((ix) => (sql += ix.indexdef + ";\n"));
          sql += "\n";
        }
      }
    }

    // --- FOREIGN KEY CONSTRAINTS (all schemas) ---
    {
      const { data: fkRows, error: fkErr } = await rpcClient.rpc<
        {
          fk_schema: string;
          fk_name: string;
          table_schema: string;
          table_name: string;
          column_names: string[];
          foreign_table_schema: string;
          foreign_table_name: string;
          foreign_column_names: string[];
        }[]
      >("pg_list_foreign_keys");
      if (fkErr) throw fkErr;
      if (fkRows && fkRows.length) {
        sql += "-- FOREIGN KEY CONSTRAINTS\n";
        fkRows.forEach((fk) => {
          const cols = fk.column_names.join(", ");
          const fcols = fk.foreign_column_names.join(", ");
          sql += `ALTER TABLE ${fk.table_schema}.${fk.table_name}\n`;
          sql += `  ADD CONSTRAINT ${fk.fk_name}\n`;
          sql += `  FOREIGN KEY (${cols}) REFERENCES ${fk.foreign_table_schema}.${fk.foreign_table_name}(${fcols});\n\n`;
        });
      }
    }

    // --- DATA INSERTS (paginated per schema) ---
    for (const sel of selections.filter((s) => s.selected)) {
      const { schema, table } = sel;

      // Create a client scoped to this particular schema
      const dataClient = createClient(url, key, {
        db: { schema },
        global: { headers: { Accept: "application/json" } }
      });

      let offset = 0;
      const pageSize = 500;
      while (true) {
        const { data: rows, error: dataErr } = await dataClient
          .from(table)
          .select("*")
          .range(offset, offset + pageSize - 1);

        if (dataErr) throw dataErr;
        if (!rows || rows.length === 0) break;

        const cols = Object.keys(rows[0] as Record<string, any>);
        const vals = (rows as any[]).map((row) => {
          const rowVals = cols.map((c) => {
            const v = row[c];
            if (v === null) return "NULL";
            if (typeof v === "string") return `'${v.replace(/'/g, "''")}'`;
            return v.toString();
          });
          return `(${rowVals.join(", ")})`;
        });

        sql += `-- Data for ${schema}.${table} OFFSET ${offset}\n`;
        sql += `INSERT INTO ${schema}.${table} (${cols.join(
          ", "
        )}) VALUES\n${vals.join(",\n")};\n\n`;

        if (rows.length < pageSize) break;
        offset += pageSize;
      }
    }

    // Send back as plain text
    res.setHeader("Content-Type", "text/plain");
    return res.status(200).send(sql);
  } catch (e: any) {
    console.error("generate-sql error:", e);
    return res.status(500).send(e.message);
  }
}