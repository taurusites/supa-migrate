import type { NextApiRequest, NextApiResponse } from "next";
import { createClient } from "@supabase/supabase-js";
import { TableSelection } from "../../types";

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<string | { error: string }>
) {
  try {
    const url = req.headers["x-sb-url"] as string;
    const key = req.headers["x-sb-key"] as string;
    if (!url || !key) throw new Error("Missing Supabase URL/key headers");

    // RPC client on public schema
    const rpcClient = createClient(url, key, {
      global: { headers: { Accept: "application/json" } }
    });

    const { selections } = req.body as { selections: TableSelection[] };
    let sql = "-- Generated by Supabase Migration Tool\n\n";

    // 1) ENUM types
    {
      const r = await rpcClient.rpc("pg_list_enum_types");
      if (r.error) throw r.error;
      const enums = r.data as Array<{
        type_schema: string;
        type_name: string;
        labels: string[];
      }> | null;
      if (enums && enums.length) {
        sql += "-- ENUM TYPES\n";
        enums.forEach((e) => {
          const vals = e.labels.map((l) => `'${l.replace(/'/g, "''")}'`);
          sql += `CREATE TYPE ${e.type_schema}.${e.type_name} AS ENUM (${vals.join(
            ", "
          )});\n`;
        });
        sql += "\n";
      }
    }

    // 2) DDL, constraints, indexes
    for (const sel of selections.filter((s) => s.selected)) {
      const { schema, table } = sel;

      // a) CREATE TABLE DDL
      {
        const r = await rpcClient.rpc("pg_get_tabledef", {
          schemaname: schema,
          tablename: table
        });
        if (r.error) throw r.error;
        const ddlRows = r.data as Array<{ ddl: string }> | null;
        const ddl = ddlRows?.[0]?.ddl || "";
        sql += `-- DDL for ${schema}.${table}\n${ddl};\n\n`;
      }

      // b) PK & UNIQUE constraints
      {
        const r = await rpcClient.rpc("pg_list_constraints", {
          schemaname: schema,
          tablename: table
        });
        if (r.error) throw r.error;
        const cons = r.data as Array<{
          constraint_name: string;
          definition: string;
        }> | null;
        if (cons && cons.length) {
          sql += `-- Constraints for ${schema}.${table}\n`;
          cons.forEach((c) => {
            sql += `ALTER TABLE ${schema}.${table}\n`
              + `  ADD CONSTRAINT ${c.constraint_name} ${c.definition};\n`;
          });
          sql += "\n";
        }
      }

      // c) Indexes
      {
        const r = await rpcClient.rpc("pg_list_indexes", {
          schemaname: schema,
          tablename: table
        });
        if (r.error) throw r.error;
        const idxs = r.data as Array<{ indexdef: string }> | null;
        if (idxs && idxs.length) {
          sql += `-- Indexes for ${schema}.${table}\n`;
          idxs.forEach((ix) => (sql += ix.indexdef + ";\n"));
          sql += "\n";
        }
      }
    }

    // 3) Foreign keys
    {
      const r = await rpcClient.rpc("pg_list_foreign_keys");
      if (r.error) throw r.error;
      const fks = r.data as Array<{
        fk_schema: string;
        fk_name: string;
        table_schema: string;
        table_name: string;
        column_names: string[];
        foreign_table_schema: string;
        foreign_table_name: string;
        foreign_column_names: string[];
      }> | null;
      if (fks && fks.length) {
        sql += "-- FOREIGN KEY CONSTRAINTS\n";
        fks.forEach((fk) => {
          const cols = fk.column_names.join(", ");
          const fcols = fk.foreign_column_names.join(", ");
          sql += `ALTER TABLE ${fk.table_schema}.${fk.table_name}\n`
            + `  ADD CONSTRAINT ${fk.fk_name}\n`
            + `  FOREIGN KEY (${cols}) REFERENCES ${fk.foreign_table_schema}.${fk.foreign_table_name}(${fcols});\n\n`;
        });
      }
    }

    // 4) Data inserts (paginated per schema)
    for (const sel of selections.filter((s) => s.selected)) {
      const { schema, table } = sel;
      const dataClient = createClient(url, key, {
        db: { schema },
        global: { headers: { Accept: "application/json" } }
      });

      let offset = 0;
      const pageSize = 500;
      while (true) {
        const { data: rows, error: dErr } = await dataClient
          .from(table)
          .select("*")
          .range(offset, offset + pageSize - 1);
        if (dErr) throw dErr;
        if (!rows || (rows as any[]).length === 0) break;

        const batch = rows as any[];
        const cols = Object.keys(batch[0]);
        const vals = batch.map((row) => {
          const parts = cols.map((c) => {
            const v = row[c];
            if (v === null) return "NULL";
            if (typeof v === "string") return `'${v.replace(/'/g, "''")}'`;
            return v.toString();
          });
          return `(${parts.join(", ")})`;
        });

        sql += `-- Data for ${schema}.${table} OFFSET ${offset}\n`;
        sql += `INSERT INTO ${schema}.${table} (${cols.join(
          ", "
        )}) VALUES\n${vals.join(",\n")};\n\n`;

        if (batch.length < pageSize) break;
        offset += pageSize;
      }
    }

    res.setHeader("Content-Type", "text/plain");
    return res.status(200).send(sql);
  } catch (e: any) {
    console.error("generate-sql error", e);
    return res.status(500).send(e.message);
  }
}